{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dev2/lib/python3.7/site-packages/socks.py:58: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n",
      "/anaconda3/envs/dev2/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dplython import (DplyFrame, X, diamonds, select, sift, sample_n, sample_frac, arrange, mutate, group_by, summarize)\n",
    "\n",
    "import plotly.plotly\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "\n",
    "from util_functions import *\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "in_data_path = '/Users/genie/data/oflc/kaggle/h1b_data_fy2011_fy2018_20190309.csv'\n",
    "cities_data_path = '/Users/genie/data/oflc/us_cities.csv'\n",
    "# cities_data_path = '/Users/genie/data/oflc/uscitiesv1.3.csv'\n",
    "coli_data_path = '/Users/genie/data/numbeo/cost-of-living/cost-of-living-2018.csv'\n",
    "metro_data_path = '/Users/genie/data/oflc/metro_areas_by_county.csv'\n",
    "\n",
    "out_dir = '/Users/genie/dev/projects/github/h1b_data_analysis/out'\n",
    "# out_dir = '/Users/genie/dev/projects/github/genielab_github_io/assets/custom/h1b_data_analysis/'\n",
    "os.chdir(out_dir)\n",
    "\n",
    "include_plotlyjs=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dev2/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning:\n",
      "\n",
      "Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(in_data_path,quotechar='\"',na_values='',encoding = \"ISO-8859-1\")\n",
    "cities_df = pd.read_csv(cities_data_path,quotechar='\"',na_values='',encoding = \"ISO-8859-1\")\n",
    "metro_df = pd.read_csv(metro_data_path,quotechar='\"',na_values='',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing/New Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['case_submitted','decision_date','full_time_position'],axis=1)\n",
    "\n",
    "# we need to derive all these variables again as they are not accurate, should be dropped in next kaggle dataset version\n",
    "df = df.drop(['county_fips','county_name','metro','lat','lng'], axis=1)\n",
    "\n",
    "df['state'] = df.apply(lambda x: x['work_state'] if pd.notnull(x['work_state']) else x['emp_state'] ,axis=1)\n",
    "df['city'] = df.apply(derive_city_variable, axis=1)\n",
    "\n",
    "df.city[(pd.notnull(df.city)) & (df.city.str.match(\"Newyork\")==True)] = \"New York\"\n",
    "df.city[(pd.notnull(df.city)) & (df.city.str.match(\"New York City\")==True)] = \"New York\"\n",
    "df.city[(pd.notnull(df.city)) & (df.city.str.match(\"Santa Clara\")==True)] = \"Santa Clara\"\n",
    "df.city[(pd.notnull(df.city)) & (df.city.str.match(\"San Fransisco\")==True)] = \"San Francisco\"\n",
    "\n",
    "df['city_state'] = df.apply(lambda x: ','.join([x['city'].title(),x['state']]) if pd.notnull(x['city']) and pd.notnull(x['state']) else None,axis=1)\n",
    "\n",
    "df = df.drop(['emp_city','emp_state','emp_zip','work_city','work_state','work_zip'], axis=1)\n",
    "\n",
    "df = pd.merge(df, cities_df[['city_name','state_id','county_fips','county_name']], how='left', left_on=['city','state'], right_on=['city_name','state_id'])\n",
    "df = df.drop(['city_name','state_id'],axis=1)\n",
    "\n",
    "df = pd.merge(df, metro_df[['county_fips','metro_name']], how='left', left_on='county_fips', right_on='county_fips')\n",
    "df.rename(columns={'metro_name':'metro'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fiscal year counts - overall\n",
    "df1 = DplyFrame(df) >> sift(X.case_status.notnull()) >> group_by(X.fiscal_year) >> summarize(fy_total=X.case_status.count())\n",
    "df2 = DplyFrame(df) >> sift(X.case_status==\"C\") >> group_by(X.fiscal_year) >> summarize(fy_certified=X.case_status.count())\n",
    "oflc_fy_counts = pd.merge(df1,df2,on='fiscal_year')\n",
    "\n",
    "del df1\n",
    "del df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart\n",
    "# fiscal year counts - by state\n",
    "\n",
    "df1 = DplyFrame(df) >> sift(X.case_status.notnull(),X.state.notnull()) >> group_by(X.fiscal_year, X.state) >> summarize(fy_state_total=X.case_status.count())\n",
    "df2 = DplyFrame(df) >> sift(X.case_status==\"C\",X.state.notnull()) >> group_by(X.fiscal_year, X.state) >> summarize(fy_certified_state=X.case_status.count())\n",
    "df1 = pd.merge(df1,df2,on=['fiscal_year','state'])\n",
    "del df2\n",
    "\n",
    "oflc_fy_state_counts = pd.merge(df1, oflc_fy_counts, how='left', on='fiscal_year')\n",
    "del df1\n",
    "\n",
    "oflc_fy_state_counts['fy_state_total_share_pct'] =  oflc_fy_state_counts.apply(lambda x: round(x['fy_state_total']/x['fy_total'] * 100,2), axis=1)\n",
    "oflc_fy_state_counts['fy_state_certified_share_pct'] =  oflc_fy_state_counts.apply(lambda x: round(x['fy_certified_state']/x['fy_certified'] * 100,2), axis=1)\n",
    "oflc_fy_state_counts = oflc_fy_state_counts.drop(['fy_certified_state','fy_total','fy_certified'],axis=1)\n",
    "\n",
    "zmin = oflc_fy_state_counts['fy_state_total'].min()\n",
    "zmax = oflc_fy_state_counts['fy_state_total'].max()\n",
    "\n",
    "scl = [[0.0, '#ffffff'],[0.2, '#ff9999'],[0.4, '#ff4d4d'], [0.6, '#ff1a1a'],[0.8, '#cc0000'],[1.0, '#4d0000']] # reds\n",
    "\n",
    "# create data for slider\n",
    "data_slider = []\n",
    "for year in oflc_fy_state_counts.fiscal_year.unique():\n",
    "    df_temp = oflc_fy_state_counts[(oflc_fy_state_counts['fiscal_year']== year)]\n",
    "    \n",
    "    for col in df_temp.columns:\n",
    "        df_temp[col] = df_temp[col].astype(str)\n",
    "    \n",
    "    df_temp['text'] = 'FY' + df_temp['fiscal_year'] + ' Share (%) ' + df_temp['fy_state_total_share_pct'] \n",
    "    \n",
    "    data_temp = dict(\n",
    "        type='choropleth',\n",
    "        colorscale = scl,\n",
    "        zmin=zmin, \n",
    "        zmax=zmax,\n",
    "        autocolorscale = False,\n",
    "        locations = df_temp['state'],\n",
    "        z = df_temp['fy_state_total'].astype(float),\n",
    "        locationmode = 'USA-states',\n",
    "        text = df_temp['text'],\n",
    "        marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),\n",
    "        colorbar = dict(title = \"Total applications\"))\n",
    "    \n",
    "    data_slider.append(data_temp)\n",
    "\n",
    "# create steps\n",
    "steps = []\n",
    "for i in range(len(data_slider)):\n",
    "    step = dict(method='restyle',\n",
    "                args=['visible', [False] * len(data_slider)],\n",
    "                label='Year {}'.format(i + 2011)) # label to be displayed for each step (year)\n",
    "    step['args'][1][i] = True\n",
    "    steps.append(step)\n",
    "\n",
    "\n",
    "sliders = [dict(active=0, pad={\"t\": 1}, steps=steps)] \n",
    "\n",
    "layout = go.Layout(title=go.layout.Title(text='2011-2018 Statewide H-1B Application Volume<br>(Hover for breakdown)'),\n",
    "                   geo=go.layout.Geo(scope='usa',projection=go.layout.geo.Projection(type='albers usa'),\n",
    "                                     showlakes=True,lakecolor = 'rgb(255, 255, 255)'),\n",
    "                   sliders=sliders)\n",
    "\n",
    "fig = go.Figure(data = data_slider, layout = layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_statewide_dist.html', validate=True)\n",
    "\n",
    "del oflc_fy_state_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_city_dist.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chart\n",
    "# fiscal year counts by city\n",
    "\n",
    "df1 = DplyFrame(df) >> sift(X.case_status.notnull(),X.city_state.notnull()) >> group_by(X.fiscal_year, X.city_state) >> summarize(fy_city_total=X.case_status.count())\n",
    "\n",
    "oflc_fy_city_counts = pd.merge(df1, oflc_fy_counts, how='left', on='fiscal_year')\n",
    "del df1\n",
    "\n",
    "oflc_fy_city_counts['fy_city_total_share_pct'] =  oflc_fy_city_counts.apply(lambda x: round(x['fy_city_total']/x['fy_total'] * 100,2), axis=1)\n",
    "oflc_fy_city_counts = DplyFrame(oflc_fy_city_counts) >> sift(X.fy_city_total>50) >> select(X.fiscal_year,X.city_state,X.fy_city_total,X.fy_city_total_share_pct)\n",
    "oflc_fy_city_counts['key'] = oflc_fy_city_counts['city_state'].apply(lambda x: x.upper() if x is not None else None) \n",
    "\n",
    "cities_df['key'] = cities_df.apply(lambda x: x['city_name'] + ',' + x['state_id'], axis=1)\n",
    "\n",
    "oflc_fy_city_counts = pd.merge(oflc_fy_city_counts, cities_df, how='left', on='key')\n",
    "del cities_df\n",
    "\n",
    "oflc_fy_city_counts = oflc_fy_city_counts.drop(['key'],axis=1)\n",
    "oflc_fy_city_counts = oflc_fy_city_counts.dropna()\n",
    "\n",
    "x_min = float(oflc_fy_city_counts['fy_city_total'].min())\n",
    "x_max = float(oflc_fy_city_counts['fy_city_total'].max())\n",
    "norm_x = 10.0\n",
    "norm_y = 50.0\n",
    "\n",
    "oflc_fy_city_counts['size'] = oflc_fy_city_counts.apply(lambda x : round(norm_x + (norm_y-norm_x)*(x['fy_city_total']-x_min)/(x_max-x_min),0), axis=1)\n",
    "\n",
    "scl = [[0.0,'#ffe5e5'],[0.1, '#ffcccc'], [0.2, '#ffb2b2'], [0.3, '#ff9999'],[0.4, '#ff7f7f'], [0.5, '#ff6666'], [0.6, '#ff4c4c'], [0.7, '#ff3232'], \n",
    "       [0.8, '#ff1919'], [0.9, '#ff0000'], [1.0, '#cc0000']] # reds\n",
    "\n",
    "cmax=oflc_fy_city_counts['fy_city_total'].max()\n",
    "\n",
    "# create data for slider\n",
    "data_slider = []\n",
    "for year in oflc_fy_city_counts.fiscal_year.unique():\n",
    "    df_temp = oflc_fy_city_counts[(oflc_fy_city_counts['fiscal_year']== year)]\n",
    "    \n",
    "    for col in df_temp.columns:\n",
    "        df_temp[col] = df_temp[col].astype(str)\n",
    "    \n",
    "    df_temp['text'] = df_temp['city_state'] + '<br>FY' + df_temp['fiscal_year'] + ' Total Applications:' + df_temp['fy_city_total'] + '<br>Share (%) ' + df_temp['fy_city_total_share_pct'] \n",
    "    \n",
    "    data_temp = go.Scattergeo(\n",
    "#         type='scattergeo',\n",
    "        locationmode = 'USA-states',\n",
    "        lon = df_temp['lng'].astype(float),\n",
    "        lat = df_temp['lat'].astype(float),\n",
    "        text = df_temp['text'],\n",
    "        mode = 'markers',\n",
    "        marker = dict( \n",
    "            size = df_temp['size'].astype(float), \n",
    "            opacity = 0.8,\n",
    "            symbol = 'circle',\n",
    "            line = dict(\n",
    "                width=1,\n",
    "                color='rgba(102, 102, 102)'\n",
    "            ),\n",
    "            cmin = 0,\n",
    "            cmax = cmax,\n",
    "            colorscale=scl,\n",
    "            autocolorscale = False,\n",
    "#             reversescale = True,\n",
    "            color = df_temp['fy_city_total'].astype(float),\n",
    "            colorbar=dict(\n",
    "                title=\"H-1B distributions by city\"\n",
    "            )\n",
    "        ))\n",
    "    \n",
    "    data_slider.append(data_temp)\n",
    "\n",
    "# create steps\n",
    "steps = []\n",
    "for i in range(len(data_slider)):\n",
    "    step = dict(method='restyle',\n",
    "                args=['visible', [False] * len(data_slider)],\n",
    "                label='Year {}'.format(i + 2011)) # label to be displayed for each step (year)\n",
    "    step['args'][1][i] = True\n",
    "    steps.append(step)\n",
    "\n",
    "\n",
    "sliders = [dict(active=0, pad={\"t\": 1}, steps=steps)] \n",
    "\n",
    "layout = dict(\n",
    "        title = '2011-2018 H-1B distributions by city', \n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showland = True,\n",
    "            showlakes=True,lakecolor = 'rgb(255, 255, 255)',\n",
    "            landcolor = \"rgb(250, 250, 250)\",\n",
    "            subunitcolor = \"rgb(217, 217, 217)\",\n",
    "            countrycolor = \"rgb(217, 217, 217)\",\n",
    "            countrywidth = 0.5,\n",
    "            subunitwidth = 0.5        \n",
    "        ),\n",
    "        sliders=sliders\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data = data_slider, layout = layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_city_dist.html', validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary Analysis in Selected Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metros = ['Seattle', 'SF Bay Area', 'Dallas', 'Miami','Atlanta', 'Detroit-Ann Arbor', 'Boston', 'Los Angeles', 'New York-Newark',\n",
    "       'Charlotte', 'Chicago', 'Tampa', 'Raleigh-Durham', 'Austin', 'Pittsburgh', 'San Diego','Washington DC', 'Philadelphia', 'Milwaukee', \n",
    "       'Phoenix', 'Houston','Denver', 'Minneapolis-St.Paul', 'St. Louis', 'Nashville', 'Orlando', 'Kansas City', 'Las Vegas','Sacremento', \n",
    "        'Richmond', 'Portland', 'Tulsa', 'Anchorage', 'Honolulu']\n",
    "\n",
    "selected_metros = sorted(selected_metros)\n",
    "\n",
    "df_certified_2018 = df[(df.fiscal_year==2018) & (df.case_status==\"C\") & (pd.notnull(df.metro)) & (df.metro.isin(selected_metros))]\n",
    "df_certified_2018['avg_annual_wage'] = df_certified_2018.apply(calc_emp_avg_annual_wage, axis=1)\n",
    "\n",
    "# oflc_2018_selected_metros = df[(df.fiscal_year==2018) & (df.case_status==\"C\") & (df.metro.isin(selected_metros))]\n",
    "# oflc_2018_selected_metros['avg_annual_wage'] = oflc_2018_selected_metros.apply(calc_emp_avg_annual_wage, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federal income tax\n",
    "df_certified_2018['federal_income_tax'] = df_certified_2018.apply(federal_income_tax_2018,axis=1)\n",
    "\n",
    "# print(df_certified_2018['state'].unique())\n",
    "# selected_states = list(df_certified_2018['state'].unique())\n",
    "\n",
    "# defualt state tax rate for tax free states\n",
    "df_certified_2018['state_income_tax_rate'] = df_certified_2018.apply(lambda x: 0, axis=1)\n",
    "df_certified_2018['state_income_tax'] = df_certified_2018.apply(lambda x: 0, axis=1)\n",
    "\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state.isin(['WA','TX','AK','FL','NV'])] = df_certified_2018.apply(lambda x: 0, axis=1)\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"MI\"] = df_certified_2018.apply(lambda x: 4.25, axis=1)\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"MA\"] = df_certified_2018.apply(lambda x: 5.10, axis=1)\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"NC\"] = df_certified_2018.apply(lambda x: 5.50, axis=1)\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"IL\"] = df_certified_2018.apply(lambda x: 4.95, axis=1)\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"PA\"] = df_certified_2018.apply(lambda x: 3.07, axis=1)\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"CO\"] = df_certified_2018.apply(lambda x: 4.63, axis=1)\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"IN\"] = df_certified_2018.apply(lambda x: 3.23, axis=1)\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"TN\"] = df_certified_2018.apply(lambda x: 3.00, axis=1)\n",
    "\n",
    "# tax brackets for selected states\n",
    "# https://taxfoundation.org/\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"CA\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,8223,19495,30769,42711,53980,275738,330884,551473,1000000,np.inf], \n",
    "                                                                                labels=[1.00,2.00,3.00,4.00,8.00,9.30,10.30,11.30,12.30,13.30])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"GA\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,750,2250,2750,5250,7000,np.inf], \n",
    "                                                                                labels=[1.00,2.00,3.00,4.00,5.00,6.00])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"AZ\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,10346,25861,51721,155159, np.inf], \n",
    "                                                                     labels=[2.59,2.88,3.36,4.24,4.54])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"NJ\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,20000,35000,40000,75000,500000, np.inf], \n",
    "                                                                     labels=[1.40,1.75,3.50,5.53,6.37,8.97])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"NY\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,8500,11700,13900,21400,80650,215400,1077550, np.inf], \n",
    "                                                                     labels=[4.00,4.50,5.25,5.90,6.33,6.57,6.85,8.82])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"MD\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,1000,2000,3000,100000,125000,150000,250000, np.inf], \n",
    "                                                                     labels=[2.00,3.00,4.00,4.75,5.00,5.25,5.50,5.75])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"WI\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,11230,22470,247350, np.inf], \n",
    "                                                                     labels=[4.00,5.84,6.27,7.65])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"VA\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,3000,5000,17000, np.inf], \n",
    "                                                                     labels=[2.00,3.00,5.00,5.75])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"MN\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,25890,85060,160020, np.inf], \n",
    "                                                                     labels=[5.35,7.05,7.85,9.85])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"DC\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,10000,40000,60000,350000,1000000, np.inf], \n",
    "                                                                     labels = [4.00,6.00,6.50,8.50,8.75,8.95])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"MO\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[100,1008,2016,3024,4032,5040,6048,7056,8064,9072, np.inf], \n",
    "                                                                     labels = [1.50,2.00,2.50,3.00,3.50,4.00,4.50,5.00,5.50,5.90])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"KS\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[2500,15000,30000, np.inf], \n",
    "                                                                     labels = [3.10,5.25,5.70])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"OR\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,3450,8700,125000, np.inf], \n",
    "                                                                     labels = [5.00,7.00,9.00,9.90])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"OK\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,1000,2500,3750,4900,7200, np.inf], \n",
    "                                                                     labels = [0.50,1.00,2.00,3.00,4.00,5.00])\n",
    "df_certified_2018.state_income_tax_rate[df_certified_2018.state==\"HI\"] = pd.cut(df_certified_2018['avg_annual_wage'], bins=[0,2400,4800,9600,14400,19200,24000,36000,48000,150000,175000,200000, np.inf], \n",
    "                                                                     labels = [1.40,3.20,5.50,6.40,6.80,7.20,7.60,7.90,8.25,9.00,10.00,11.00])\n",
    "\n",
    "df_certified_2018['state_income_tax'] = df_certified_2018.apply(lambda x: round(x['state_income_tax_rate']*x['avg_annual_wage']/100,2), axis=1)\n",
    "\n",
    "# https://www.irs.gov/taxtopics/tc751\n",
    "df_certified_2018['social_security_tax'] = df_certified_2018.apply(lambda x: round(6.2*x['avg_annual_wage']/100,2) if x['avg_annual_wage']<128400.00 else round(6.2*128400.00/100,2), axis=1)\n",
    "df_certified_2018['medicare_tax'] = df_certified_2018.apply(lambda x: round(1.45*x['avg_annual_wage']/100,2), axis=1)\n",
    "\n",
    "df_certified_2018['all_taxes'] = df_certified_2018.apply(lambda x: x['federal_income_tax']+x['state_income_tax']+x['social_security_tax']+x['medicare_tax'], axis=1)\n",
    "df_certified_2018['wage_after_taxes'] = df_certified_2018.apply(lambda x: x['avg_annual_wage']-x['all_taxes'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_selected_cities_percentile_salary_2018.html'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## selected cities - salary percentile plot\n",
    "\n",
    "x_lables=selected_metros\n",
    "y_labels=['P25','P50','P75','P90']\n",
    "\n",
    "x_metro_data=[]\n",
    "for x_metro in selected_metros:\n",
    "    x_metro_values = df_certified_2018[df_certified_2018.metro==x_metro]['avg_annual_wage'].values\n",
    "    q25, q50, q75, q90 = np.percentile(x_metro_values,[25,50,75,90])\n",
    "    x_metro_data.append([round(q25,2),round(q50,2),round(q75,2),round(q90,2)])\n",
    "\n",
    "traces = []\n",
    "for ylabel_idx,y_label in enumerate(y_labels):\n",
    "    ylabel_data_points = [x_metro_data[metro_idx][ylabel_idx] for metro_idx in range(len(x_metro_data))]\n",
    "    traces.append(go.Bar(x=selected_metros,y=ylabel_data_points,name=y_labels[ylabel_idx]))\n",
    "    \n",
    "data = [traces[i] for i in range(len(traces))]\n",
    "\n",
    "layout = go.Layout(barmode='stack', title='Gross Salary Percentile Distribution in Selected Cities (FY-2018)',yaxis=dict(title='Salary (Cumulative)'))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_cities_percentile_salary_2018.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # chart\n",
    "# # selected cities - salary percentile plot  (Modified)\n",
    "# # includes all information in one plot\n",
    "\n",
    "# def hover_for_salary_percentile_plot(avg_taxes, avg_wage_after_taxes, taxes_pct):\n",
    "#     result = 'Avg taxes paid by this segment ~ ' + str(convert_amount_to_human_format(avg_taxes)) + '<br>Avg wage after tax ~ ' + str(convert_amount_to_human_format(avg_wage_after_taxes)) + '<br>' + str(taxes_pct) + '% of H1B Taxes in this city' \n",
    "#     return(result)\n",
    "\n",
    "\n",
    "# x_lables=selected_metros\n",
    "# y_labels=['<P25 (Bottom 25%)','<P50 (Median)','>P75 (Top 25%)','>P90 (Top 10%)']\n",
    "\n",
    "# x_metro_data=[]\n",
    "# y_labels_hover_text=[]\n",
    "# for x_metro in selected_metros:\n",
    "#     x_metro_values = df_certified_2018[df_certified_2018.metro==x_metro]['avg_annual_wage'].values\n",
    "#     q25, q50, q75, q90 = np.percentile(x_metro_values,[25,50,75,90])\n",
    "    \n",
    "#     x_metro_sum_alltaxes = np.nansum(df_certified_2018[df_certified_2018.metro==x_metro]['all_taxes'].values)\n",
    "    \n",
    "#     q25_avg_taxes = np.nanmean(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage<q25)]['all_taxes'].values)\n",
    "#     q25_avg_wage_after_taxes = np.nanmean(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage<q25)]['wage_after_taxes'].values)\n",
    "#     q25_taxes_pct = round(np.nansum(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage<q25)]['all_taxes'].values)/x_metro_sum_alltaxes*100,2)\n",
    "    \n",
    "#     q50_avg_taxes = np.nanmean(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage<q50)]['all_taxes'].values)\n",
    "#     q50_avg_wage_after_taxes = np.nanmean(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage<q50)]['wage_after_taxes'].values)\n",
    "#     q50_taxes_pct = round(np.nansum(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage<q50)]['all_taxes'].values)/x_metro_sum_alltaxes*100,2)\n",
    "    \n",
    "#     top25_avg_taxes = np.nanmean(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage>=q75)]['all_taxes'].values)\n",
    "#     top25_avg_wage_after_taxes = np.nanmean(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage>=q75)]['wage_after_taxes'].values)\n",
    "#     top25_taxes_pct = round(np.nansum(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage>=q75)]['all_taxes'].values)/x_metro_sum_alltaxes*100,2)\n",
    "    \n",
    "#     top10_avg_taxes = np.nanmean(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage>=q90)]['all_taxes'].values)\n",
    "#     top10_avg_wage_after_taxes = np.nanmean(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage>=q90)]['wage_after_taxes'].values)\n",
    "#     top10_taxes_pct = round(np.nansum(df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage>=q90)]['all_taxes'].values)/x_metro_sum_alltaxes*100,2)\n",
    "    \n",
    "#     x_metro_data.append([round(q25,2),round(q50,2),round(q75,2),round(q90,2)])\n",
    "#     y_labels_hover_text.append( [hover_for_salary_percentile_plot(q25_avg_taxes,q25_avg_wage_after_taxes,q25_taxes_pct), \n",
    "#                                  hover_for_salary_percentile_plot(q50_avg_taxes,q50_avg_wage_after_taxes,q50_taxes_pct), \n",
    "#                                  hover_for_salary_percentile_plot(top25_avg_taxes,top25_avg_wage_after_taxes,top25_taxes_pct), \n",
    "#                                  hover_for_salary_percentile_plot(top10_avg_taxes,top10_avg_wage_after_taxes,top10_taxes_pct)])\n",
    "    \n",
    "\n",
    "# traces = []\n",
    "# for ylabel_idx,y_label in enumerate(y_labels):\n",
    "#     ylabel_data_points = [x_metro_data[metro_idx][ylabel_idx] for metro_idx in range(len(x_metro_data))]\n",
    "#     ylabel_hover_text = [y_labels_hover_text[idx][ylabel_idx] for idx in range(len(y_labels_hover_text))]\n",
    "#     traces.append(go.Bar(x=selected_metros,y=ylabel_data_points,text=ylabel_hover_text,name=y_labels[ylabel_idx]))\n",
    "    \n",
    "# data = [traces[i] for i in range(len(traces))]\n",
    "\n",
    "# layout = go.Layout(barmode='stack', title='Gross Salary Percentile Distribution in Selected Cities (FY-2018)',yaxis=dict(title='Salary (Cumulative)'))\n",
    "\n",
    "# fig = go.Figure(data=data, layout=layout)\n",
    "# plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_cities_percentile_salary_2018.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_selected_cities_outliers_2018.html'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chart\n",
    "# selected cities - outliers\n",
    "\n",
    "x_lables=selected_metros\n",
    "y_labels=['Low Income Segment <P25-1.5*IQR','Affluent Segment >P75+1.5*IQR']\n",
    "\n",
    "x_metro_data=[]\n",
    "y_labels_hover_text=[]\n",
    "for x_metro in selected_metros:\n",
    "    x_metro_values = df_certified_2018[df_certified_2018.metro==x_metro]['avg_annual_wage'].values\n",
    "    q25, q75 = np.percentile(x_metro_values,[25,75])\n",
    "    IQR = q75-q25\n",
    "    \n",
    "    l_outlier_wage = q25-1.5*IQR\n",
    "    h_outlier_wage = q75+1.5*IQR\n",
    "    \n",
    "    l_outliers = list(filter(lambda x: x < l_outlier_wage ,x_metro_values))\n",
    "    h_outliers = list(filter(lambda x: x > h_outlier_wage ,x_metro_values))\n",
    "    x_metro_data.append([round(len(l_outliers)/len(x_metro_values)*100,2), round(len(h_outliers)/len(x_metro_values)*100,2)])\n",
    "    \n",
    "    y_labels_hover_text.append(\n",
    "        [\n",
    "            'Wage < ' + str(convert_amount_to_human_format(l_outlier_wage)),\n",
    "            'Wage > ' + str(convert_amount_to_human_format(h_outlier_wage))\n",
    "        ])\n",
    "\n",
    "traces = []\n",
    "for ylabel_idx,y_label in enumerate(y_labels):\n",
    "    ylabel_data_points = [x_metro_data[metro_idx][ylabel_idx] for metro_idx in range(len(x_metro_data))]\n",
    "    ylabel_hover_text = [y_labels_hover_text[idx][ylabel_idx] for idx in range(len(y_labels_hover_text))]\n",
    "    traces.append(go.Bar(x=selected_metros,y=ylabel_data_points,text=ylabel_hover_text, name=y_labels[ylabel_idx]))\n",
    "    \n",
    "data = [traces[i] for i in range(len(traces))]\n",
    "\n",
    "layout = go.Layout(barmode='stack',title='Outlier Population Proportions in Selected Cities (FY-2018)',\n",
    "                   yaxis=dict(title='% of H1B certified population'), legend=dict(x=0,y=1,traceorder='normal',orientation=\"h\"))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_cities_outliers_2018.html')\n",
    "\n",
    "\n",
    "# def hover_for_outlier_salary_percentile_plot(avg_taxes, taxes_pct):\n",
    "#     result =  'Avg taxes paid by this segment ~ ' + str(convert_amount_to_human_format(avg_taxes)) + '<br>' + str(taxes_pct) + '% of H1B Taxes in this city' \n",
    "#     return(result)\n",
    "\n",
    "# x_lables=selected_metros\n",
    "# y_labels=['Low Income Segment <P25-1.5*IQR','Affluent Segment >P75+1.5*IQR']\n",
    "\n",
    "# x_metro_data=[]\n",
    "# y_labels_hover_text=[]\n",
    "# for x_metro in selected_metros:\n",
    "#     x_metro_values = df_certified_2018[df_certified_2018.metro==x_metro]['avg_annual_wage'].values\n",
    "    \n",
    "#     q25, q75 = np.percentile(x_metro_values,[25,75])\n",
    "#     IQR = q75-q25\n",
    "    \n",
    "#     l_outlier_wage = q25-1.5*IQR\n",
    "#     h_outlier_wage = q75+1.5*IQR\n",
    "    \n",
    "#     l_outliers = list(filter(lambda x: x < l_outlier_wage ,x_metro_values))\n",
    "#     h_outliers = list(filter(lambda x: x > h_outlier_wage ,x_metro_values))\n",
    "    \n",
    "#     x_metro_taxes = df_certified_2018[df_certified_2018.metro==x_metro]['all_taxes'].values\n",
    "    \n",
    "#     h_outliers_taxes = df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage>=h_outlier_wage)]['all_taxes'].values\n",
    "#     h_outliers_avg_taxes = np.nanmean(h_outliers_taxes)\n",
    "#     h_outliers_taxes_pct = round(np.nansum(h_outliers_taxes)/np.nansum(x_metro_taxes)*100, 2)\n",
    "    \n",
    "#     l_outliers_taxes = df_certified_2018[(df_certified_2018.metro==x_metro) & (df_certified_2018.avg_annual_wage<=l_outlier_wage)]['all_taxes'].values\n",
    "#     l_outliers_avg_taxes = np.nanmean(l_outliers_taxes) if len(l_outliers_taxes)>0 else 0\n",
    "#     l_outliers_taxes_pct = round(np.nansum(l_outliers_taxes)/np.nansum(x_metro_taxes)*100, 2)\n",
    "    \n",
    "#     x_metro_data.append([round(len(l_outliers)/len(x_metro_values)*100,2), round(len(h_outliers)/len(x_metro_values)*100,2)])\n",
    "#     y_labels_hover_text.append(\n",
    "#         [\n",
    "#             'Wage < ' + str(convert_amount_to_human_format(l_outlier_wage)) + '<br>' + hover_for_outlier_salary_percentile_plot(l_outliers_avg_taxes, l_outliers_taxes_pct),\n",
    "#             'Wage > ' + str(convert_amount_to_human_format(h_outlier_wage)) + '<br>' + hover_for_outlier_salary_percentile_plot(h_outliers_avg_taxes, h_outliers_taxes_pct)\n",
    "#         ])\n",
    "\n",
    "# traces = []\n",
    "# for ylabel_idx,y_label in enumerate(y_labels):\n",
    "#     ylabel_data_points = [x_metro_data[metro_idx][ylabel_idx] for metro_idx in range(len(x_metro_data))]\n",
    "#     ylabel_hover_text = [y_labels_hover_text[idx][ylabel_idx] for idx in range(len(y_labels_hover_text))]\n",
    "#     traces.append(go.Bar(x=selected_metros,y=ylabel_data_points,text=ylabel_hover_text, name=y_labels[ylabel_idx]))\n",
    "    \n",
    "# data = [traces[i] for i in range(len(traces))]\n",
    "\n",
    "# layout = go.Layout(barmode='stack',title='Outlier Population Proportions in Selected Cities (FY-2018)',\n",
    "#                    yaxis=dict(title='% of H1B certified population'), legend=dict(x=0,y=1,traceorder='normal',orientation=\"h\"))\n",
    "\n",
    "# fig = go.Figure(data=data, layout=layout)\n",
    "# plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_cities_outliers_2018.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart\n",
    "# Gini in selected cities 2018\n",
    "\n",
    "# x_lables=selected_metros\n",
    "# y_labels=['Gini Index (Income Disparity)']\n",
    "\n",
    "# x_metro_data=[]\n",
    "# for x_metro in selected_metros:\n",
    "#     x_metro_values = df_certified_2018[df_certified_2018.metro==x_metro]['avg_annual_wage'].values\n",
    "#     x_metro_gini = gini(x_metro_values)\n",
    "#     x_metro_data.append(round(x_metro_gini,2))\n",
    "\n",
    "# traces = []\n",
    "# ylabel_data_points = [x_metro_data[metro_idx] for metro_idx in range(len(x_metro_data))]\n",
    "# traces.append(go.Bar(x=selected_metros,y=ylabel_data_points))\n",
    "    \n",
    "# data = [traces[i] for i in range(len(traces))]\n",
    "\n",
    "# layout = go.Layout(barmode='stack', title='Gini Index for Selected Cities (FY-2018)',yaxis=dict(title='Salary (Cumulative)'))\n",
    "\n",
    "# fig = go.Figure(data=data, layout=layout)\n",
    "# plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_cities_gini_2018.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_selected_cities_gini.html'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chart\n",
    "# Gini in selected cities, 2011-2018\n",
    "\n",
    "df1 = df[(df.case_status==\"C\") & (df.metro.isin(selected_metros))]\n",
    "fiscal_years = sorted(df1['fiscal_year'].unique())\n",
    "traces_a = []\n",
    "for x_metro in selected_metros:\n",
    "    y_values = []\n",
    "    for year in fiscal_years:\n",
    "        df_temp = df1[(df1.fiscal_year==year) & (df1.metro==x_metro)]\n",
    "        df_temp['avg_annual_wage'] = df_temp.apply(calc_emp_avg_annual_wage,axis=1)\n",
    "        values = df_temp['avg_annual_wage'].values\n",
    "        values = values[np.isfinite(values)]\n",
    "        x_metro_gini = gini(values)\n",
    "        y_values.append(round(x_metro_gini,2))\n",
    "    traces_a.append(go.Scatter(x=fiscal_years,y=y_values, name=x_metro))\n",
    "\n",
    "data = [traces_a[i] for i in range(len(traces_a))]\n",
    "layout = go.Layout(title='Gini in Selected Cities (2011-2018)',yaxis=dict(title='Gini Index'), hovermode='closest')\n",
    "fig = go.Figure(data,layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_cities_gini.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_selected_cities_median_salary.html'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chart\n",
    "# Median salary in selected cities, 2011-2018\n",
    "\n",
    "df1 = df[(df.case_status==\"C\") & (df.metro.isin(selected_metros))]\n",
    "fiscal_years = sorted(df1['fiscal_year'].unique())\n",
    "traces_a = []\n",
    "for x_metro in selected_metros:\n",
    "    y_values = []\n",
    "    for year in fiscal_years:\n",
    "        df_temp = df1[(df1.fiscal_year==year) & (df1.metro==x_metro)]\n",
    "        df_temp['avg_annual_wage'] = df_temp.apply(calc_emp_avg_annual_wage,axis=1)\n",
    "        q50 = np.nanpercentile(df_temp['avg_annual_wage'].values,50)\n",
    "        y_values.append(q50)\n",
    "    traces_a.append(go.Scatter(x=fiscal_years,y=y_values, name=x_metro))\n",
    "\n",
    "data = [traces_a[i] for i in range(len(traces_a))]\n",
    "layout = go.Layout(title='Median Salary in Selected Cities (2011-2018)',yaxis=dict(title='Median salary'), hovermode='closest')\n",
    "fig = go.Figure(data,layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_cities_median_salary.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employer analysis\n",
    "\n",
    "# df1 = df[(df.case_status==\"C\") & (df.emp_name.notnull()==True)]\n",
    "df1 = df[df.emp_name.notnull()==True]\n",
    "df1['emp_name_x'] = df1['emp_name']\n",
    "\n",
    "#employer data cleansing\n",
    "df1.emp_name_x[df1.emp_name.str.match('INFOSYS')] = 'INFOSYS'\n",
    "df1.emp_name_x[df1.emp_name.str.match('WIPRO')] = 'WIPRO'\n",
    "df1.emp_name_x[df1.emp_name.str.match('TATA')] = 'TATA (TCS)'\n",
    "df1.emp_name_x[df1.emp_name.str.match('COGNIZANT')] = 'COGNIZANT'\n",
    "df1.emp_name_x[df1.emp_name.str.match('CAPGEMINI')] = 'CAPGEMINI'\n",
    "df1.emp_name_x[df1.emp_name.str.match('DELOITTE')] = 'DELOITTE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('TECH MAHINDRA')] = 'TECH MAHINDRA'\n",
    "df1.emp_name_x[df1.emp_name.str.match('IBM')]='IBM'\n",
    "df1.emp_name_x[df1.emp_name.str.match('L&T|(?=.*LARSEN)(?=.*TOUBRO)')] = 'L&T'\n",
    "df1.emp_name_x[df1.emp_name.str.match('ACCENTURE')] = 'ACCENTURE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('HCL')] = 'HCL'\n",
    "df1.emp_name_x[df1.emp_name.str.match('IGATE')] = 'IGATE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('UST GLOBAL')] = 'UST GLOBAL'\n",
    "df1.emp_name_x[df1.emp_name.str.match('(?=.*SYNTEL)(?!.*SYNTELLI|SYNTELLIA)')] = 'SYNTEL'\n",
    "\n",
    "df1.emp_name_x[df1.emp_name.str.match('PRICEWATERHOUSECOOPERS')] = 'PWC'\n",
    "df1.emp_name_x[df1.emp_name.str.match('(?=.*ERNST)(?=.*YOUNG)')] = 'ERNST & YOUNG'\n",
    "df1.emp_name_x[df1.emp_name.str.match('VISA U.S.A.')] = 'VISA'\n",
    "df1.emp_name_x[df1.emp_name.str.match('CITIBANK|CITIGROUP|CITICORP|CITIFINANCIAL|CITIMORTGAGE|CITI VENTURES|CITI HEDGE FUND')] = 'CITIBANK'\n",
    "df1.emp_name_x[df1.emp_name.str.match('DISCOVER PRODUCTS|DISCOVER GROUP|DISCOVER BANK')] = 'DISCOVER'\n",
    "df1.emp_name_x[df1.emp_name.str.match('JPMORGAN')] = 'JPMORGAN CHASE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('(?=.*AMERICAN EXPRESS)(?!.*LOGISTICS)')] = 'AMERICAN EXPRESS'\n",
    "df1.emp_name_x[df1.emp_name.str.match('WELLS FARGO')] = 'WELLS FARGO'\n",
    "df1.emp_name_x[df1.emp_name.str.match('BANK OF AMERICA')] = 'BANK OF AMERICA'\n",
    "df1.emp_name_x[df1.emp_name.str.match('(?=.*CAPITAL ONE)(?!.*CONSTRUCTION)')] = 'CAPITAL ONE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('GOLDMAN SACH')] = 'GOLDMAN SACH'\n",
    "df1.emp_name_x[df1.emp_name.str.match('MORGAN STANLEY')] = 'MORGAN STANLEY'\n",
    "\n",
    "df1.emp_name_x[df1.emp_name.str.match('AMAZON')] = 'AMAZON'\n",
    "df1.emp_name_x[df1.emp_name.str.match('GOOGLE')] = 'GOOGLE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('FACEBOOK')] = 'FACEBOOK'\n",
    "df1.emp_name_x[df1.emp_name.str.match('APPLE INC')] = 'APPLE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('TESLA')] = 'TESLA'\n",
    "df1.emp_name_x[df1.emp_name.str.match('MICROSOFT')] = 'MICROSOFT'\n",
    "df1.emp_name_x[df1.emp_name.str.match('YAHOO')] = 'YAHOO'\n",
    "df1.emp_name_x[df1.emp_name.str.match('ORACLE AMERICA|ORACLE FINANCIAL|ORACLE USA')] = 'ORACLE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('NETFLIX')] = 'NETFLIX'\n",
    "df1.emp_name_x[df1.emp_name.str.match('UBERCAB|UBER, INC|UBER TECHNOLOGIES')] = 'UBER'\n",
    "df1.emp_name_x[df1.emp_name.str.match('AIRBNB')] = 'AIRBNB'\n",
    "df1.emp_name_x[df1.emp_name.str.match('QUALCOMM')] = 'QUALCOMM'\n",
    "df1.emp_name_x[df1.emp_name.str.match('INTEL CORPORATION|INTEL AMERICA|INTEL INC')] = 'INTEL'\n",
    "df1.emp_name_x[df1.emp_name.str.match('CISCO SYSTEMS|CISCO SYSTEM|CISCO CONSUMER|CISCO FC')] = 'CISCO'\n",
    "\n",
    "df1.emp_name_x[df1.emp_name.str.match('WAL-MART')] = 'WALMART'\n",
    "df1.emp_name_x[df1.emp_name.str.match('COSTCO')] = 'COSTCO'\n",
    "df1.emp_name_x[df1.emp_name.str.match('HOME DEPOT')] = 'HOME DEPOT'\n",
    "df1.emp_name_x[df1.emp_name.str.match('MACYS')] = 'MACYS'\n",
    "df1.emp_name_x[df1.emp_name.str.match('VERIZON')] = 'VERIZON'\n",
    "df1.emp_name_x[df1.emp_name.str.match('AT&T')] = 'AT&T'\n",
    "\n",
    "df1.emp_name_x[df1.emp_name.str.match('CHEVRON')] = 'CHEVRON'\n",
    "df1.emp_name_x[df1.emp_name.str.match('EXXON MOBIL|EXXONMOBIL')] = 'EXXON MOBIL'\n",
    "df1.emp_name_x[df1.emp_name.str.match('BP AMERICA')] = 'BRITISH PETROLEUM (BP)'\n",
    "df1.emp_name_x[df1.emp_name.str.match('SHELL EXPLORATION|SHELL INTERNATIONAL|SHELL GLOBAL|SHELL OIL')] = 'SHELL OIL'\n",
    "\n",
    "df1.emp_name_x[df1.emp_name.str.match('MASTECH DIGITAL')] = 'MASTECH'\n",
    "df1.emp_name_x[df1.emp_name.str.match('NTT DATA')] = 'NTT DATA'\n",
    "df1.emp_name_x[df1.emp_name.str.match('SALESFORCE.COM')] = 'SALESFORCE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('LINKEDIN')] = 'LINKEDIN'\n",
    "df1.emp_name_x[df1.emp_name.str.match('VIRTUSA')] = 'VIRTUSA'\n",
    "df1.emp_name_x[df1.emp_name.str.match('VMWARE')] = 'VMWARE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('PAYPAL')] = 'PAYPAL'\n",
    "df1.emp_name_x[df1.emp_name.str.match('EBAY')] = 'EBAY'\n",
    "df1.emp_name_x[df1.emp_name.str.match('HEXAWARE')] = 'HEXAWARE'\n",
    "df1.emp_name_x[df1.emp_name.str.match('FUJITSU AMERICA')] = 'FUJITSU AMERICA'\n",
    "df1.emp_name_x[df1.emp_name.str.match('EMC CORPORATION')] = 'EMC'\n",
    "df1.emp_name_x[df1.emp_name.str.match('SATYAM COMPUTER SERVICES')] = 'SATYAM COMPUTER SERVICES'\n",
    "df1.emp_name_x[df1.emp_name.str.match('PATNI AMERICAS')] = 'PATNI'\n",
    "\n",
    "df1['avg_annual_wage'] = df1.apply(calc_emp_avg_annual_wage, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_popular_employers.html'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Popular Employers, who hires a lot?\n",
    "\n",
    "# prepare data\n",
    "df2 = df1[df1.case_status.isin([\"C\",\"CW\"])].groupby(['fiscal_year','emp_name_x'])['case_status'].size().to_frame().reset_index()\n",
    "df2.rename(columns={'case_status':'fy_company_certified_count'}, inplace=True)\n",
    "\n",
    "fiscal_years = list(df2['fiscal_year'].unique())\n",
    "\n",
    "emp_names = []\n",
    "for year in fiscal_years:\n",
    "    df_x = df2[df2.fiscal_year==year].sort_values(by=['fy_company_certified_count'],ascending=False).head(20)\n",
    "    for emp in df_x['emp_name_x']:\n",
    "        if(emp not in emp_names):\n",
    "            emp_names.append(emp)\n",
    "emp_names = list(set(emp_names))\n",
    "del df2\n",
    "\n",
    "selected_companies = ['INFOSYS','WIPRO','TATA (TCS)','COGNIZANT','CAPGEMINI','DELOITTE','IBM',\n",
    "                      'CITIBANK','AMERICAN EXPRESS','BANK OF AMERICA','CAPITAL ONE','JPMORGAN CHASE','WELLS FARGO',\n",
    "                      'AMAZON','GOOGLE','MICROSOFT','ORACLE','APPLE','TESLA','NETFLIX','UBER','FACEBOOK', 'AIRBNB','INTEL','CISCO',\n",
    "                      'CHEVRON','EXXON MOBIL','SHELL OIL','BRITISH PETROLEUM (BP)','WALMART','COSTCO','VERIZON','AT&T']\n",
    "\n",
    "emp_names = emp_names + selected_companies\n",
    "emp_names = list(set(emp_names))\n",
    "emp_names = sorted(emp_names)\n",
    "\n",
    "df2 = df1[df1.emp_name_x.isin(emp_names)].groupby(['fiscal_year','emp_name_x'])['case_status'].size().to_frame().reset_index()\n",
    "df2.rename(columns={'case_status':'fy_company_count'}, inplace=True)\n",
    "df3 = df1[df1.case_status.isin([\"C\",\"CW\"])].groupby(['fiscal_year','emp_name_x'])['case_status'].size().to_frame().reset_index()\n",
    "df3.rename(columns={'case_status':'fy_company_certified_count'}, inplace=True)\n",
    "df2 = pd.merge(df2,df3,on=['fiscal_year','emp_name_x'])\n",
    "del df3\n",
    "df2['approval_rate'] = df2.apply(lambda x: round(x['fy_company_certified_count']/x['fy_company_count']*100,2), axis=1)\n",
    "\n",
    "df3 = df1[(df1.case_status==\"C\") & (df1.emp_name_x.isin(emp_names))]\n",
    "df3 = df3.groupby(['fiscal_year','emp_name_x'])['avg_annual_wage'].median().to_frame().reset_index()\n",
    "df3.rename(columns={'avg_annual_wage':'avg_annual_median_wage'}, inplace=True)\n",
    "df2 = pd.merge(df2,df3,on=['fiscal_year','emp_name_x'])\n",
    "del df3\n",
    "\n",
    "df2['category'] = df2['emp_name_x']\n",
    "df2.category[df2.emp_name_x.str.match('ACCENTURE|CAPGEMINI|COGNIZANT|DELOITTE|FUJITSU|HCL|IBM|IGATE|INFOSYS|L&T|PATNI|SATYAM|SYNTEL|TATA|TECH MAHINDRA|UST GLOBAL|WIPRO')] = 'CONSULTING'\n",
    "df2.category[df2.emp_name_x.str.match('AMAZON|APPLE|CISCO|FACEBOOK|GOOGLE|INTEL|MICROSOFT|NETFLIX|ORACLE|QUALCOMM|TESLA|UBER|AIRBNB')] = 'TECH'\n",
    "df2.category[df2.emp_name_x.str.match('AMERICAN EXPRESS|BANK OF AMERICA|CAPITAL ONE|CITIBANK|ERNST & YOUNG|JPMORGAN CHASE|PWC|WELLS FARGO')] = 'FINANCIAL'\n",
    "df2.category[df2.emp_name_x.str.match('AT&T|VERIZON')] = 'TELECOM'\n",
    "df2.category[df2.emp_name_x.str.match('BRITISH|CHEVRON|SHELL|EXXON')] = 'OIL SECTOR'\n",
    "df2.category[df2.emp_name_x.str.match('WALMART|COSTCO')] = 'RETAIL'\n",
    "\n",
    "df2['text'] = df2.apply(lambda x: x['emp_name_x'] + '<br>No of Certified LCA(s): ' + str(x['fy_company_certified_count']) , axis=1)\n",
    "# chart\n",
    "categories = list(df2['category'].unique())\n",
    "\n",
    "figure = {\n",
    "    'data': [],\n",
    "    'layout': {},\n",
    "    'frames': []\n",
    "}\n",
    "\n",
    "figure['layout']['xaxis'] = {'range': [80, 100], 'title': 'Approval Rate'}\n",
    "figure['layout']['yaxis'] = {'range': [20000, np.nanmax(df2['avg_annual_median_wage'])] , 'title': 'Median Salary'}\n",
    "figure['layout']['title'] = 'Popular Employers (2011-2018)<br><span style=\"font-size:x-small;width:50%;\">NOTE: This is an interactive chart, please hover over individual bubbles for more detailed information. Also you may selectively enable or disable legend items to isolate individual category or more.</span>'\n",
    "\n",
    "figure['layout']['hovermode'] = 'closest'\n",
    "figure['layout']['legend'] = { 'font' : {'family':'sans-serif','size':12} }\n",
    "figure['layout']['sliders'] = {\n",
    "    'args': [\n",
    "        'transition', {\n",
    "            'duration': 400,\n",
    "            'easing': 'cubic-in-out'\n",
    "        }\n",
    "    ],\n",
    "    'initialValue': '1952',\n",
    "    'plotlycommand': 'animate',\n",
    "    'values': fiscal_years,\n",
    "    'visible': True\n",
    "}\n",
    "figure['layout']['updatemenus'] = [\n",
    "    {\n",
    "        'buttons': [\n",
    "            {\n",
    "                'args': [None, {'frame': {'duration': 500, 'redraw': False},\n",
    "                         'fromcurrent': True, 'transition': {'duration': 300, 'easing': 'quadratic-in-out'}}],\n",
    "                'label': 'Play',\n",
    "                'method': 'animate'\n",
    "            },\n",
    "            {\n",
    "                'args': [[None], {'frame': {'duration': 0, 'redraw': False}, 'mode': 'immediate',\n",
    "                'transition': {'duration': 0}}],\n",
    "                'label': 'Pause',\n",
    "                'method': 'animate'\n",
    "            }\n",
    "        ],\n",
    "        'direction': 'left',\n",
    "        'pad': {'r': 10, 't': 87},\n",
    "        'showactive': False,\n",
    "        'type': 'buttons',\n",
    "        'x': 0.1,\n",
    "        'xanchor': 'right',\n",
    "        'y': 0,\n",
    "        'yanchor': 'top'\n",
    "    }\n",
    "]\n",
    "sliders_dict = {\n",
    "    'active': 0,\n",
    "    'yanchor': 'top',\n",
    "    'xanchor': 'left',\n",
    "    'currentvalue': {\n",
    "        'font': {'size': 20},\n",
    "        'prefix': 'Year:',\n",
    "        'visible': True,\n",
    "        'xanchor': 'right'\n",
    "    },\n",
    "    'transition': {'duration': 300, 'easing': 'cubic-in-out'},\n",
    "    'pad': {'b': 10, 't': 50},\n",
    "    'len': 0.9,\n",
    "    'x': 0.1,\n",
    "    'y': 0,\n",
    "    'steps': []\n",
    "}\n",
    "\n",
    "# make data\n",
    "year = fiscal_years[0]\n",
    "for category in categories:\n",
    "    dataset_by_year = df2[df2.fiscal_year == year]\n",
    "    dataset_by_year_and_cat = dataset_by_year[dataset_by_year.category == category]\n",
    "\n",
    "    data_dict = {\n",
    "        'x': list(dataset_by_year_and_cat['approval_rate']),\n",
    "        'y': list(dataset_by_year_and_cat['avg_annual_median_wage']),\n",
    "        'mode': 'markers',\n",
    "        'text': list(dataset_by_year_and_cat['text']),\n",
    "        'marker': {\n",
    "            'sizemode': 'area',\n",
    "            'sizeref': 1,\n",
    "            'size': list(dataset_by_year_and_cat['fy_company_certified_count'])\n",
    "        },\n",
    "        'name': category\n",
    "    }\n",
    "    figure['data'].append(data_dict)\n",
    "    \n",
    "# make frames\n",
    "for year in fiscal_years:\n",
    "    frame = {'data': [], 'name': str(year)}\n",
    "    for category in categories:\n",
    "        dataset_by_year = df2[df2.fiscal_year == year]\n",
    "        dataset_by_year_and_cat = dataset_by_year[dataset_by_year.category == category]\n",
    "\n",
    "        data_dict = {\n",
    "            'x': list(dataset_by_year_and_cat['approval_rate']),\n",
    "            'y': list(dataset_by_year_and_cat['avg_annual_median_wage']),\n",
    "            'mode': 'markers',\n",
    "            'text': list(dataset_by_year_and_cat['text']),\n",
    "            'marker': {\n",
    "                'sizemode': 'area',\n",
    "                'sizeref': 1,\n",
    "                'size': list(dataset_by_year_and_cat['fy_company_certified_count'])\n",
    "            },\n",
    "            'name': category\n",
    "        }\n",
    "        frame['data'].append(data_dict)\n",
    "\n",
    "    figure['frames'].append(frame)\n",
    "    slider_step = {'args': [\n",
    "        [year],\n",
    "        {'frame': {'duration': 300, 'redraw': False},\n",
    "         'mode': 'immediate',\n",
    "       'transition': {'duration': 300}}\n",
    "     ],\n",
    "     'label': str(year),\n",
    "     'method': 'animate'}\n",
    "    sliders_dict['steps'].append(slider_step)\n",
    "\n",
    "    \n",
    "figure['layout']['sliders'] = [sliders_dict]\n",
    "\n",
    "plotly.offline.plot(figure, include_plotlyjs=include_plotlyjs, filename='oflc_popular_employers.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_companies = ['INFOSYS','WIPRO','TATA (TCS)','COGNIZANT','CAPGEMINI','DELOITTE','IBM',\n",
    "                      'CITIBANK','AMERICAN EXPRESS','BANK OF AMERICA','CAPITAL ONE','JPMORGAN CHASE','WELLS FARGO',\n",
    "                      'AMAZON','GOOGLE','MICROSOFT','ORACLE','APPLE','TESLA','NETFLIX','UBER','FACEBOOK', 'AIRBNB','INTEL','CISCO',\n",
    "                      'CHEVRON','EXXON MOBIL','SHELL OIL','BRITISH PETROLEUM (BP)','WALMART','COSTCO','VERIZON','AT&T'\n",
    "                     ]\n",
    "\n",
    "selected_companies = sorted(selected_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_selected_companies_percentile_salary_2018.html'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chart\n",
    "# selected companies - salary percentile plot\n",
    "\n",
    "oflc_2018_selected_companies = df1[(df1.fiscal_year==2018) & (df1.case_status==\"C\") & (df1.emp_name_x.isin(selected_companies))]\n",
    "oflc_2018_selected_companies['avg_annual_wage'] = oflc_2018_selected_companies.apply(calc_emp_avg_annual_wage, axis=1)\n",
    "\n",
    "x_lables=selected_companies\n",
    "y_labels=['P25','P50','P75','P90']\n",
    "\n",
    "x_emp_data=[]\n",
    "for x_emp in selected_companies:\n",
    "    x_emp_values = oflc_2018_selected_companies[oflc_2018_selected_companies.emp_name_x==x_emp]['avg_annual_wage'].values\n",
    "    q25, q50, q75, q90 = np.percentile(x_emp_values,[25,50,75,90])\n",
    "    x_emp_data.append([round(q25,2),round(q50,2),round(q75,2),round(q90,2)])\n",
    "\n",
    "traces = []\n",
    "for ylabel_idx,y_label in enumerate(y_labels):\n",
    "    ylabel_data_points = [x_emp_data[emp_idx][ylabel_idx] for emp_idx in range(len(x_emp_data))]\n",
    "    traces.append(go.Bar(x=selected_companies,y=ylabel_data_points,name=y_labels[ylabel_idx]))\n",
    "    \n",
    "data = [traces[i] for i in range(len(traces))]\n",
    "\n",
    "layout = go.Layout(barmode='stack', title='Percentile-Salary Distribution in Selected Companies (FY-2018)',yaxis=dict(title='Salary (Cumulative)'))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_companies_percentile_salary_2018.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_selected_companies_outliers_2018.html'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chart\n",
    "# selected companies - outliers\n",
    "x_lables=selected_companies\n",
    "y_labels=['Low Income Segment <P25-1.5*IQR','Affluent Segment >P75+1.5*IQR']\n",
    "\n",
    "x_emp_data=[]\n",
    "y_labels_hover_text=[]\n",
    "for x_emp in selected_companies:\n",
    "    x_metro_values = oflc_2018_selected_companies[oflc_2018_selected_companies.emp_name_x==x_emp]['avg_annual_wage'].values\n",
    "    \n",
    "    q25, q75 = np.percentile(x_metro_values,[25,75])\n",
    "    IQR = q75-q25\n",
    "    \n",
    "    l_outlier_wage = q25-1.5*IQR\n",
    "    h_outlier_wage = q75+1.5*IQR\n",
    "    \n",
    "    l_outliers = list(filter(lambda x: x < l_outlier_wage, x_metro_values))\n",
    "    h_outliers = list(filter(lambda x: x > h_outlier_wage, x_metro_values))\n",
    "    \n",
    "    x_emp_data.append([round(len(l_outliers)/len(x_metro_values)*100,2), round(len(h_outliers)/len(x_metro_values)*100,2)])\n",
    "    y_labels_hover_text.append(\n",
    "        [\n",
    "            'Wage < ' + str(convert_amount_to_human_format(l_outlier_wage)),\n",
    "            'Wage > ' + str(convert_amount_to_human_format(h_outlier_wage))\n",
    "        ])\n",
    "\n",
    "traces = []\n",
    "for ylabel_idx,y_label in enumerate(y_labels):\n",
    "    ylabel_data_points = [x_emp_data[emp_idx][ylabel_idx] for emp_idx in range(len(x_emp_data))]\n",
    "    ylabel_hover_text = [y_labels_hover_text[idx][ylabel_idx] for idx in range(len(y_labels_hover_text))]\n",
    "    traces.append(go.Bar(x=selected_companies,y=ylabel_data_points,text=ylabel_hover_text, name=y_labels[ylabel_idx]))\n",
    "    \n",
    "data = [traces[i] for i in range(len(traces))]\n",
    "\n",
    "layout = go.Layout(barmode='stack',title='Outlier Population Proportions in Selected Companies (FY-2018)',\n",
    "                   yaxis=dict(title='% of H1B certified population'), legend=dict(x=0,y=1,traceorder='normal',orientation=\"h\"))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_companies_outliers_2018.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_selected_companies_median_salary.html'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chart\n",
    "# Median salary in selected companies, 2011-2018\n",
    "\n",
    "dfx = df1[(df1.case_status==\"C\") & (df1.emp_name_x.isin(selected_companies))]\n",
    "fiscal_years = sorted(dfx['fiscal_year'].unique())\n",
    "traces_a = []\n",
    "for x_emp in selected_companies:\n",
    "    y_values = []\n",
    "    for year in fiscal_years:\n",
    "        df_temp = dfx[(dfx.fiscal_year==year) & (dfx.emp_name_x==x_emp)]\n",
    "        if(len(df_temp)>0):\n",
    "            df_temp['avg_annual_wage'] = df_temp.apply(calc_emp_avg_annual_wage,axis=1)\n",
    "            q50, q90 = np.percentile(df_temp['avg_annual_wage'].values,[50,90])\n",
    "            y_values.append(q50)\n",
    "        else:\n",
    "            y_values.append(np.nan)\n",
    "    traces_a.append(go.Scatter(x=fiscal_years,y=y_values, name=x_emp))\n",
    "\n",
    "data = [traces_a[i] for i in range(len(traces_a))]\n",
    "layout = go.Layout(title='Median Salary in Selected Companies (2011-2018)',yaxis=dict(title='Median salary'), hovermode='closest')\n",
    "fig = go.Figure(data,layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_companies_median_salary.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_selected_companies_gini.html'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chart\n",
    "# Gini in selected companies, 2011-2018\n",
    "\n",
    "dfx = df1[(df1.case_status==\"C\") & (df1.emp_name_x.isin(selected_companies))]\n",
    "fiscal_years = sorted(dfx['fiscal_year'].unique())\n",
    "traces_a = []\n",
    "for x_emp in selected_companies:\n",
    "    y_values = []\n",
    "    for year in fiscal_years:\n",
    "        df_temp = dfx[(dfx.fiscal_year==year) & (dfx.emp_name_x==x_emp)]\n",
    "        if(len(df_temp)>0):\n",
    "            df_temp['avg_annual_wage'] = df_temp.apply(calc_emp_avg_annual_wage,axis=1)\n",
    "            values = df_temp['avg_annual_wage'].values\n",
    "            values = values[np.isfinite(values)]\n",
    "            x_emp_gini = gini(values)\n",
    "            y_values.append(round(x_emp_gini,2))\n",
    "        else:\n",
    "            y_values.append(np.nan)\n",
    "    traces_a.append(go.Scatter(x=fiscal_years,y=y_values, name=x_emp))\n",
    "\n",
    "data = [traces_a[i] for i in range(len(traces_a))]\n",
    "layout = go.Layout(title='Gini in Selected Companies (2011-2018)',yaxis=dict(title='Gini Index'), hovermode='closest')\n",
    "fig = go.Figure(data,layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_companies_gini.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/genie/dev/projects/github/h1b_data_analysis/out/oflc_selected_companies_approval_rates.html'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chart\n",
    "# Application Volume and Approval rate plots of selected companies, 2011-2018\n",
    "\n",
    "df2 = df1.groupby(['fiscal_year','emp_name_x'])['case_status'].size().to_frame().reset_index()\n",
    "df2.rename(columns={'case_status':'fy_company_count'}, inplace=True)\n",
    "\n",
    "df3 = df1[df1.case_status.isin([\"C\",\"CW\"])].groupby(['fiscal_year','emp_name_x'])['case_status'].size().to_frame().reset_index()\n",
    "df3.rename(columns={'case_status':'fy_company_certified_count'}, inplace=True)\n",
    "\n",
    "df2 = pd.merge(df2,df3,on=['fiscal_year','emp_name_x'])\n",
    "\n",
    "df2['approval_rate'] = df2.apply(lambda x: round(x['fy_company_certified_count']/x['fy_company_count']*100,2), axis=1)\n",
    "df2 = df2.drop(['fy_company_certified_count'],axis=1)\n",
    "\n",
    "del df3\n",
    "\n",
    "fiscal_years = sorted(df2['fiscal_year'].unique())\n",
    "traces_a = []\n",
    "for x_emp in selected_companies:\n",
    "    y_values = []\n",
    "    for year in fiscal_years:\n",
    "        df_temp = df2[(df2.fiscal_year==year) & (df2.emp_name_x==x_emp)]\n",
    "        if(len(df_temp)>0):\n",
    "            y_values.append(df_temp['fy_company_count'].values[0])\n",
    "        else:\n",
    "            y_values.append(np.nan)\n",
    "    traces_a.append(go.Scatter(x=fiscal_years,y=y_values, name=x_emp))\n",
    "\n",
    "data = [traces_a[i] for i in range(len(traces_a))]\n",
    "layout = go.Layout(title='Application Volume of Selected Companies (2011-2018)',yaxis=dict(title='Application Volume'), hovermode='closest')\n",
    "fig = go.Figure(data,layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_companies_application_volume.html')\n",
    "\n",
    "traces_a = []\n",
    "for x_emp in selected_companies:\n",
    "    y_values = []\n",
    "    for year in fiscal_years:\n",
    "        df_temp = df2[(df2.fiscal_year==year) & (df2.emp_name_x==x_emp)]\n",
    "        if(len(df_temp)>0):\n",
    "            y_values.append(df_temp['approval_rate'].values[0])\n",
    "        else:\n",
    "            y_values.append(np.nan)\n",
    "    traces_a.append(go.Scatter(x=fiscal_years,y=y_values, name=x_emp))\n",
    "\n",
    "data = [traces_a[i] for i in range(len(traces_a))]\n",
    "layout = go.Layout(title='Approval Rates of Selected Companies (2011-2018)',yaxis=dict(title='Approval Percentage'), hovermode='closest')\n",
    "fig = go.Figure(data,layout)\n",
    "plotly.offline.plot(fig, include_plotlyjs=include_plotlyjs, filename='oflc_selected_companies_approval_rates.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
